{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Neural Network Model\n",
    "Below a 6 layer neural network defined for binary classification of diabetes vs no diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    layers: nn.Sequential\n",
    "    def __init__(self, features) :\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(features, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to load CSV data into PyTorch dataloaders:\n",
    "class CSV_Data(Dataset):\n",
    "    def __init__(self, f):\n",
    "        self.dat = pd.read_csv(f)\n",
    "        self.y = self.dat.iloc[:, 0].to_numpy()\n",
    "        self.X = self.dat.iloc[:, 1:].to_numpy()\n",
    "    def __len__(self):\n",
    "        return len(self.dat)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN Accuracy Calculation\n",
    "\n",
    "def tester(model, testloader):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (features, label) in enumerate(testloader):\n",
    "            features = features.type(torch.float32)\n",
    "            output = model(features)\n",
    "            pred = torch.argmax(output, 1)\n",
    "            if(pred == min(1, label)):\n",
    "                correct+=1\n",
    "            total+=1\n",
    "    print(f\"Accuracy: {(correct*100)/total} \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(testloader, model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for i, (features, label) in enumerate(testloader):\n",
    "        features = features.type(torch.float32)\n",
    "        output = model(features)\n",
    "        pred = torch.argmax(output, 1)\n",
    "        y_pred.append(pred[0].item())\n",
    "        y_true.append(min(1, label[0].item()))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data: path to data csv file\n",
    "epochs: number of epochs to train for\n",
    "random_negative_drop: proportion of randomly dropped 0 labels\n",
    "'''\n",
    "def train(data, epochs, random_negative_drop):\n",
    "    \n",
    "    data = CSV_Data(data)\n",
    "    train_set, test_set = torch.utils.data.random_split(data, [int(0.75*(len(data))), len(data)- int(0.75*len(data))])\n",
    "    trainloader = DataLoader(train_set, batch_size = 1, shuffle = True)\n",
    "    testloader = DataLoader(test_set, batch_size = 1, shuffle = False)\n",
    "    # print(trainloader.size)\n",
    "    _, (f, _) = list(enumerate(trainloader))[0]\n",
    "\n",
    "    model = FCN(f.shape[1])\n",
    "    \n",
    "    weights = [20.0, 1.0]\n",
    "    class_weights = torch.FloatTensor(weights)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    tester(model, testloader)   \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        for i, (features, label) in enumerate(trainloader):\n",
    "            \n",
    "            if(( random.uniform(0.0, 1.0)> random_negative_drop  and label==0) or label!=0):\n",
    "                features = features.type(torch.float32)\n",
    "                l = [min(1, label)]\n",
    "                g = torch.Tensor(l)  \n",
    "                optimizer.zero_grad()\n",
    "                logits = model.forward(features)\n",
    "                loss = criterion(logits, g.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        tester(model, testloader)\n",
    "\n",
    "    print(\"Train Metrics:\")\n",
    "    metrics(trainloader, model)\n",
    "    print(\"Test Metrics:\")\n",
    "    metrics(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Cleaned data\n",
      "Accuracy: 12.18895186203206 \n",
      "Epoch 1\n",
      "Accuracy: 87.81104813796794 \n",
      "Epoch 2\n",
      "Accuracy: 87.81104813796794 \n",
      "Epoch 3\n",
      "Accuracy: 87.81104813796794 \n",
      "Epoch 4\n",
      "Accuracy: 87.86699423511955 \n",
      "Epoch 5\n",
      "Accuracy: 87.84753472306681 \n",
      "Train Metrics:\n",
      "Confusion Matrix\n",
      "[[108666     68]\n",
      " [ 14509     90]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94    108734\n",
      "           1       0.57      0.01      0.01     14599\n",
      "\n",
      "    accuracy                           0.88    123333\n",
      "   macro avg       0.73      0.50      0.47    123333\n",
      "weighted avg       0.85      0.88      0.83    123333\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix\n",
      "[[36078    22]\n",
      " [ 4974    37]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94     36100\n",
      "           1       0.63      0.01      0.01      5011\n",
      "\n",
      "    accuracy                           0.88     41111\n",
      "   macro avg       0.75      0.50      0.47     41111\n",
      "weighted avg       0.85      0.88      0.82     41111\n",
      "\n",
      "5050 Cleaned Data\n",
      "Accuracy: 50.35364680586205 \n",
      "Epoch 1\n",
      "Accuracy: 74.51479658235726 \n",
      "Epoch 2\n",
      "Accuracy: 74.48084648899452 \n",
      "Epoch 3\n",
      "Accuracy: 74.50913823346347 \n",
      "Epoch 4\n",
      "Accuracy: 74.02817857749109 \n",
      "Epoch 5\n",
      "Accuracy: 74.29412097549935 \n",
      "Train Metrics:\n",
      "Confusion Matrix\n",
      "[[19542  6961]\n",
      " [ 6504 20012]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74     26503\n",
      "           1       0.74      0.75      0.75     26516\n",
      "\n",
      "    accuracy                           0.75     53019\n",
      "   macro avg       0.75      0.75      0.75     53019\n",
      "weighted avg       0.75      0.75      0.75     53019\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix\n",
      "[[6503 2340]\n",
      " [2203 6627]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      8843\n",
      "           1       0.74      0.75      0.74      8830\n",
      "\n",
      "    accuracy                           0.74     17673\n",
      "   macro avg       0.74      0.74      0.74     17673\n",
      "weighted avg       0.74      0.74      0.74     17673\n",
      "\n",
      "Original Cleaned Data Random Drop\n",
      "Accuracy: 88.02753520955461 \n",
      "Epoch 1\n",
      "Accuracy: 77.48534455498529 \n",
      "Epoch 2\n",
      "Accuracy: 68.99613242197952 \n",
      "Epoch 3\n",
      "Accuracy: 65.42774439930919 \n",
      "Epoch 4\n",
      "Accuracy: 75.05533798739997 \n",
      "Epoch 5\n",
      "Accuracy: 71.03451630950354 \n",
      "Train Metrics:\n",
      "Confusion Matrix\n",
      "[[76574 32071]\n",
      " [ 3513 11175]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81    108645\n",
      "           1       0.26      0.76      0.39     14688\n",
      "\n",
      "    accuracy                           0.71    123333\n",
      "   macro avg       0.61      0.73      0.60    123333\n",
      "weighted avg       0.87      0.71      0.76    123333\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix\n",
      "[[25412 10777]\n",
      " [ 1131  3791]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81     36189\n",
      "           1       0.26      0.77      0.39      4922\n",
      "\n",
      "    accuracy                           0.71     41111\n",
      "   macro avg       0.61      0.74      0.60     41111\n",
      "weighted avg       0.87      0.71      0.76     41111\n",
      "\n",
      "5050 Cleaned Data Random Drop\n",
      "Accuracy: 50.22350478130482 \n",
      "Epoch 1\n",
      "Accuracy: 64.50517738923782 \n",
      "Epoch 2\n",
      "Accuracy: 63.967634244327506 \n",
      "Epoch 3\n",
      "Accuracy: 65.98766479941153 \n",
      "Epoch 4\n",
      "Accuracy: 63.67905845074407 \n",
      "Epoch 5\n",
      "Accuracy: 63.63945000848752 \n",
      "Train Metrics:\n",
      "Confusion Matrix\n",
      "[[ 7498 19051]\n",
      " [  435 26035]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.28      0.43     26549\n",
      "           1       0.58      0.98      0.73     26470\n",
      "\n",
      "    accuracy                           0.63     53019\n",
      "   macro avg       0.76      0.63      0.58     53019\n",
      "weighted avg       0.76      0.63      0.58     53019\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix\n",
      "[[2518 6279]\n",
      " [ 147 8729]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.29      0.44      8797\n",
      "           1       0.58      0.98      0.73      8876\n",
      "\n",
      "    accuracy                           0.64     17673\n",
      "   macro avg       0.76      0.63      0.59     17673\n",
      "weighted avg       0.76      0.64      0.59     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the data on the cleaned original dataset\n",
    "print(\"Original Cleaned data\")\n",
    "train('cleaned_diabetes.csv', 5, 0)\n",
    "      \n",
    "print(\"5050 Cleaned Data\")\n",
    "train('5050_clean_diabetes_dataset.csv', 5, 0)\n",
    "      \n",
    "print(\"Original Cleaned Data Random Drop\")\n",
    "train('cleaned_diabetes.csv', 5, 0.85)\n",
    "      \n",
    "print(\"5050 Cleaned Data Random Drop\")\n",
    "train('5050_clean_diabetes_dataset.csv', 5, 0.85)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
